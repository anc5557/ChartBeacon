import pendulum
import logging
import os
import requests  # Discord webhook
from typing import List, Dict, Any
import pandas as pd

from airflow.models.dag import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.exceptions import AirflowSkipException

logger = logging.getLogger(__name__)

# --- Environment Variables & Settings ---
DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL")
POSTGRES_CONN_ID = "postgres_default"  # Airflow UI Connection ID

# Alert Conditions
PRICE_CHANGE_THRESHOLD_PERCENT = 3.0  # %
VOLUME_SPIKE_FACTOR = 2.0  # Times average volume
VOLUME_AVG_PERIOD = 20  # Number of candles for volume average

# Bollinger Bands Settings
BBANDS_PERIOD = 20
BBANDS_STD_DEV = 2

# Support/Resistance Settings
SR_LOOKBACK_PERIOD = 50  # Number of candles to look back for dynamic S/R

# Longer Timeframe Analysis Settings
LONG_TIMEFRAME = "1h"
LONG_TIMEFRAME_CANDLES_LIMIT = 65  # EMA60 ê³„ì‚° ë“±ì„ ìœ„í•´ ì¶©ë¶„íˆ
LONG_EMA_SHORT_PERIOD = 20
LONG_EMA_LONG_PERIOD = 60

# Discord Embed Colors
COLOR_GREEN = 3066993  # ìƒìŠ¹ ê´€ë ¨
COLOR_RED = 15158332  # í•˜ë½ ê´€ë ¨
COLOR_BLUE = 3447003  # ì •ë³´/ì¤‘ë¦½ (ê±°ë˜ëŸ‰, S/R í„°ì¹˜ ë“±)
COLOR_ORANGE = 15105652  # ì£¼ì˜
COLOR_PURPLE = 10181046  # BBands
COLOR_GOLD = 15844367  # ê°•í™”ëœ ì‹ í˜¸
COLOR_SILVER = 12370112  # ì¤‘ë¦½/ì •ë³´ì„± ì‹ í˜¸
COLOR_BRONZE = 10040115  # ì•½í•œ ì‹ í˜¸ ë˜ëŠ” ì£¼ì˜

# --- Helper Functions for Longer Timeframe Analysis ---


def calculate_ema(prices: pd.Series, period: int) -> pd.Series:
    return prices.ewm(span=period, adjust=False).mean()


def get_longer_timeframe_data_sync(
    ticker: str, timeframe: str, pg_hook: PostgresHook, limit: int
) -> pd.DataFrame:
    """ì§€ì •ëœ ìƒìœ„ ì‹œê°„ë´‰ì˜ OHLCV ë° ì£¼ìš” ì§€í‘œë¥¼ ë™ê¸°ì ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    sql = """
    SELECT ts, open, high, low, close, volume
    FROM candles_raw c
    JOIN symbols s ON c.symbol_id = s.id
    WHERE s.ticker = %(ticker)s AND c.timeframe = %(timeframe)s
    ORDER BY c.ts DESC
    LIMIT %(limit)s;
    """
    try:
        records = pg_hook.get_records(
            sql, parameters={"ticker": ticker, "timeframe": timeframe, "limit": limit}
        )
        if not records or len(records) < 1:
            return pd.DataFrame()

        df = pd.DataFrame(records, columns=["ts", "open", "high", "low", "close", "volume"])
        df["ts"] = pd.to_datetime(df["ts"])
        for col in ["open", "high", "low", "close", "volume"]:
            df[col] = pd.to_numeric(df[col], errors="coerce")
        df.dropna(
            subset=["open", "high", "low", "close"], inplace=True
        )  # ì£¼ìš” ê°€ê²© ë°ì´í„° ì—†ëŠ” í–‰ ì œê±°
        df = df.iloc[::-1].reset_index(drop=True)

        if not df.empty and len(df) >= LONG_EMA_SHORT_PERIOD:  # ìµœì†Œ EMA ê³„ì‚° ê°€ëŠ¥ ì¡°ê±´
            df[f"ema{LONG_EMA_SHORT_PERIOD}"] = calculate_ema(df["close"], LONG_EMA_SHORT_PERIOD)
            if len(df) >= LONG_EMA_LONG_PERIOD:
                df[f"ema{LONG_EMA_LONG_PERIOD}"] = calculate_ema(df["close"], LONG_EMA_LONG_PERIOD)
        return df
    except Exception as e:
        logger.error(f"DB error fetching {timeframe} data for {ticker}: {e}", exc_info=True)
        return pd.DataFrame()


def analyze_long_term_context_for_signal(
    short_term_signal_type: str,
    short_term_price: float,  # 5ë¶„ë´‰ ì•Œë¦¼ ë°œìƒ ì‹œì ì˜ ê°€ê²©
    long_tf_df: pd.DataFrame,
) -> Dict[str, Any]:
    """ìƒìœ„ ì‹œê°„ë´‰ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¨ê¸° ì‹ í˜¸ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    context_summary = {
        "signal_strength": "neutral",
        "message": "ìƒìœ„ ì‹œê°„ë´‰ ë°ì´í„° ë¶€ì¡± ë˜ëŠ” ë¶„ì„ ë¶ˆê°€",
        "color": COLOR_SILVER,
    }

    if (
        long_tf_df.empty
        or len(long_tf_df) < 1
        or f"ema{LONG_EMA_SHORT_PERIOD}" not in long_tf_df.columns
    ):
        return context_summary

    latest_long_tf_candle = long_tf_df.iloc[-1]
    long_ema_short = latest_long_tf_candle.get(f"ema{LONG_EMA_SHORT_PERIOD}")
    long_ema_long = latest_long_tf_candle.get(f"ema{LONG_EMA_LONG_PERIOD}")  # ì—†ì„ ìˆ˜ë„ ìˆìŒ
    long_close = latest_long_tf_candle.get("close")

    long_term_trend_is_up = None
    trend_desc = "í˜¼ì¡°ì„¸"
    if long_close is not None and long_ema_short is not None:
        if long_ema_long is not None:  # ê¸´ EMAë„ ìˆì„ ê²½ìš°
            if long_close > long_ema_short and long_ema_short > long_ema_long:
                long_term_trend_is_up = True
                trend_desc = (
                    f"ëª…í™•í•œ ìƒìŠ¹ ì¶”ì„¸ (ì¢…ê°€>{LONG_EMA_SHORT_PERIOD}EMA>{LONG_EMA_LONG_PERIOD}EMA)"
                )
            elif long_close < long_ema_short and long_ema_short < long_ema_long:
                long_term_trend_is_up = False
                trend_desc = (
                    f"ëª…í™•í•œ í•˜ë½ ì¶”ì„¸ (ì¢…ê°€<{LONG_EMA_SHORT_PERIOD}EMA<{LONG_EMA_LONG_PERIOD}EMA)"
                )
            elif long_close > long_ema_short:  # êµì°¨ëŠ” ì—†ì§€ë§Œ ë‹¨ê¸° EMA ìœ„
                long_term_trend_is_up = "moderate_up"
                trend_desc = f"ë‹¨ê¸° ìƒìŠ¹ ìš°ìœ„ (ì¢…ê°€>{LONG_EMA_SHORT_PERIOD}EMA)"
            elif long_close < long_ema_short:  # êµì°¨ëŠ” ì—†ì§€ë§Œ ë‹¨ê¸° EMA ì•„ë˜
                long_term_trend_is_up = "moderate_down"
                trend_desc = f"ë‹¨ê¸° í•˜ë½ ìš°ìœ„ (ì¢…ê°€<{LONG_EMA_SHORT_PERIOD}EMA)"
        else:  # ì§§ì€ EMAë§Œ ìˆì„ ê²½ìš°
            if long_close > long_ema_short:
                long_term_trend_is_up = "moderate_up"
                trend_desc = f"ë‹¨ê¸° ìƒìŠ¹ ìš°ìœ„ (ì¢…ê°€>{LONG_EMA_SHORT_PERIOD}EMA)"
            elif long_close < long_ema_short:
                long_term_trend_is_up = "moderate_down"
                trend_desc = f"ë‹¨ê¸° í•˜ë½ ìš°ìœ„ (ì¢…ê°€<{LONG_EMA_SHORT_PERIOD}EMA)"

    base_message = f"{LONG_TIMEFRAME.upper()} ê¸°ì¤€: {trend_desc}."

    is_bullish_signal = (
        short_term_signal_type.endswith("_bullish")
        or "upper_break" in short_term_signal_type
        or "support_touch" in short_term_signal_type
    )
    is_bearish_signal = (
        short_term_signal_type.endswith("_bearish")
        or "lower_break" in short_term_signal_type
        or "resistance_touch" in short_term_signal_type
    )

    if is_bullish_signal:
        if long_term_trend_is_up is True:
            context_summary["signal_strength"] = "strong"
            context_summary["message"] = f"ğŸ”¥ {base_message} 5ë¶„ë´‰ ë§¤ìˆ˜ ê´€ë ¨ ì‹ í˜¸ì™€ ì¼ì¹˜!"
            context_summary["color"] = COLOR_GOLD
        elif long_term_trend_is_up == "moderate_up":
            context_summary["signal_strength"] = "moderate"
            context_summary["message"] = f"ğŸ‘ {base_message} 5ë¶„ë´‰ ë§¤ìˆ˜ ê´€ë ¨ ì‹ í˜¸ì™€ ë¶€í•©."
            context_summary["color"] = COLOR_GREEN
        elif long_term_trend_is_up is False or long_term_trend_is_up == "moderate_down":
            context_summary["signal_strength"] = "weak"
            context_summary["message"] = f"âš ï¸ {base_message} 5ë¶„ë´‰ ë§¤ìˆ˜ ê´€ë ¨ ì‹ í˜¸ì™€ ë°˜ëŒ€! ì£¼ì˜ í•„ìš”."
            context_summary["color"] = COLOR_BRONZE
        else:  # neutral
            context_summary["message"] = f"â¡ï¸ {base_message} ì‹ ì¤‘í•œ ì ‘ê·¼ í•„ìš”."
            context_summary["color"] = COLOR_SILVER

    elif is_bearish_signal:
        if long_term_trend_is_up is False:
            context_summary["signal_strength"] = "strong"
            context_summary["message"] = f"ğŸ”¥ {base_message} 5ë¶„ë´‰ ë§¤ë„ ê´€ë ¨ ì‹ í˜¸ì™€ ì¼ì¹˜!"
            context_summary["color"] = COLOR_GOLD
        elif long_term_trend_is_up == "moderate_down":
            context_summary["signal_strength"] = "moderate"
            context_summary["message"] = f"ğŸ‘ {base_message} 5ë¶„ë´‰ ë§¤ë„ ê´€ë ¨ ì‹ í˜¸ì™€ ë¶€í•©."
            context_summary["color"] = COLOR_RED
        elif long_term_trend_is_up is True or long_term_trend_is_up == "moderate_up":
            context_summary["signal_strength"] = "weak"
            context_summary["message"] = f"âš ï¸ {base_message} 5ë¶„ë´‰ ë§¤ë„ ê´€ë ¨ ì‹ í˜¸ì™€ ë°˜ëŒ€! ì£¼ì˜ í•„ìš”."
            context_summary["color"] = COLOR_BRONZE
        else:  # neutral
            context_summary["message"] = f"â¡ï¸ {base_message} ì‹ ì¤‘í•œ ì ‘ê·¼ í•„ìš”."
            context_summary["color"] = COLOR_SILVER

    elif short_term_signal_type == "volume_spike":
        context_summary["signal_strength"] = "info"
        vol_message_parts = [base_message]
        if "volume" in long_tf_df.columns and len(long_tf_df["volume"]) >= 5:
            avg_long_vol = (
                long_tf_df["volume"].iloc[-6:-1].mean() if len(long_tf_df["volume"]) > 1 else 0
            )
            curr_long_vol = long_tf_df["volume"].iloc[-1]
            if avg_long_vol > 0 and curr_long_vol > avg_long_vol * 1.5:
                vol_message_parts.append(
                    f"{LONG_TIMEFRAME.upper()}ì—ì„œë„ ê±°ë˜ëŸ‰ ì¦ê°€ì„¸ ê´€ì°°ë¨ (í˜„ì¬ {curr_long_vol:,.0f} vs í‰ê·  {avg_long_vol:,.0f})."
                )
            elif avg_long_vol > 0:
                vol_message_parts.append(
                    f"{LONG_TIMEFRAME.upper()} ê±°ë˜ëŸ‰ì€ í‰ì´í•¨ (í˜„ì¬ {curr_long_vol:,.0f} vs í‰ê·  {avg_long_vol:,.0f})."
                )
            else:
                vol_message_parts.append(f"{LONG_TIMEFRAME.upper()} ê±°ë˜ëŸ‰ ë°ì´í„° ë¶„ì„ ì¤‘.")
        context_summary["message"] = " ".join(vol_message_parts)
        context_summary["color"] = COLOR_BLUE  # ê±°ë˜ëŸ‰ì€ ì¤‘ë¦½ì  íŒŒë€ìƒ‰

    # S/Rì˜ ê²½ìš°, í•´ë‹¹ ë ˆë²¨ì´ ì¥ê¸° EMAì™€ ê°€ê¹Œìš´ì§€ ë“±ìœ¼ë¡œ ê°•í™” ê°€ëŠ¥
    if "sr_" in short_term_signal_type and (
        long_ema_short is not None or long_ema_long is not None
    ):
        sr_level_proximity_message = ""
        if (
            long_ema_short and abs(short_term_price - long_ema_short) / short_term_price < 0.005
        ):  # 0.5% ì´ë‚´
            sr_level_proximity_message = f"í•´ë‹¹ ë ˆë²¨ì€ {LONG_TIMEFRAME.upper()} EMA{LONG_EMA_SHORT_PERIOD}({long_ema_short:,.2f})ê³¼ ê·¼ì ‘."
        if long_ema_long and abs(short_term_price - long_ema_long) / short_term_price < 0.005:
            proximity_detail = f"{LONG_TIMEFRAME.upper()} EMA{LONG_EMA_LONG_PERIOD}({long_ema_long:,.2f})ê³¼ë„ ê·¼ì ‘."
            sr_level_proximity_message += (
                f" ({'ë˜í•œ ' if sr_level_proximity_message else ''}{proximity_detail})"
            )

        if sr_level_proximity_message:
            context_summary["message"] += f" {sr_level_proximity_message}"
            if (
                context_summary["signal_strength"] == "neutral"
                or context_summary["signal_strength"] == "info"
            ):  # ì¶”ì„¸ ì¤‘ë¦½ì´ì–´ë„ ê°•í™”
                context_summary["signal_strength"] = "moderate"
                # ìƒ‰ìƒì€ ê¸°ì¡´ bullish/bearish íŒë‹¨ì— ë”°ë¥´ê±°ë‚˜, S/Rì€ BLUE ìœ ì§€

    return context_summary


# --- ê¸°ì¡´ ì•Œë¦¼ í™•ì¸ í•¨ìˆ˜ë“¤ ìˆ˜ì • (ê° í•¨ìˆ˜ ë‚´ë¶€ì— ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ë¡œì§ ì¶”ê°€) ---


def get_active_symbols_task() -> List[str]:
    """Fetches active stock tickers from the database."""
    pg_hook = PostgresHook(postgres_conn_id=POSTGRES_CONN_ID)
    sql = "SELECT ticker FROM symbols WHERE active = TRUE;"
    try:
        records = pg_hook.get_records(sql)
    except Exception as e:
        logger.error(f"Failed to fetch active symbols from DB: {e}", exc_info=True)
        return []  # Return empty list on DB error to prevent downstream failures

    if not records:
        logger.info("No active symbols found.")
        return []

    active_tickers = [record[0] for record in records]
    logger.info(f"Active symbols: {active_tickers}")
    return active_tickers


def send_discord_alert(payload: Dict[str, Any], ticker: str, alert_type: str):
    """Sends an alert to Discord via webhook."""
    if not DISCORD_WEBHOOK_URL or DISCORD_WEBHOOK_URL == "YOUR_DISCORD_WEBHOOK_URL_HERE":
        logger.warning(
            f"DISCORD_WEBHOOK_URL is not set or is a placeholder. Skipping Discord notification for {ticker} ({alert_type})."
        )
        return

    try:
        response = requests.post(DISCORD_WEBHOOK_URL, json=payload, timeout=10)
        response.raise_for_status()
        logger.info(
            f"Discord alert sent for {ticker} ({alert_type}). Status: {response.status_code}"
        )
    except requests.exceptions.RequestException as e:
        logger.error(f"Failed to send Discord alert for {ticker} ({alert_type}): {e}")


def check_price_alert_for_symbol(ticker: str, pg_hook: PostgresHook):
    """Checks for significant price changes for a given ticker."""
    sql = """
    SELECT c.ts, c.close
    FROM candles_raw c
    JOIN symbols s ON c.symbol_id = s.id
    WHERE s.ticker = %(ticker)s AND c.timeframe = '5m'
    ORDER BY c.ts DESC
    LIMIT 2;
    """
    try:
        candles = pg_hook.get_records(sql, parameters={"ticker": ticker})
    except Exception as e:
        logger.error(f"DB error fetching candles for price alert ({ticker}): {e}", exc_info=True)
        return

    if not candles or len(candles) < 2:
        logger.info(
            f"Not enough 5m candle data for {ticker} to check price alert (found {len(candles) if candles else 0})."
        )
        return

    latest_candle_ts, latest_close = candles[0]
    previous_candle_ts, previous_close = candles[1]

    try:
        latest_close = float(latest_close)
        previous_close = float(previous_close)
    except (ValueError, TypeError) as e:
        logger.error(
            f"Invalid price data for {ticker}: {e}. Latest: {latest_close}, Previous: {previous_close}"
        )
        return

    if previous_close == 0:
        logger.warning(
            f"Previous close price is 0 for {ticker} at {previous_candle_ts}. Cannot calculate change."
        )
        return

    price_change_percent = ((latest_close - previous_close) / previous_close) * 100

    alert_trigger = None
    alert_description_prefix = ""
    color = COLOR_ORANGE  # Default color

    if price_change_percent >= PRICE_CHANGE_THRESHOLD_PERCENT:
        alert_trigger = "ê¸‰ë“±"
        alert_description_prefix = f"ğŸš€ **ê°€ê²© ê¸‰ë“±! {price_change_percent:+.2f}%**"
        color = COLOR_GREEN
    elif price_change_percent <= -PRICE_CHANGE_THRESHOLD_PERCENT:
        alert_trigger = "ê¸‰ë½"
        alert_description_prefix = f"ğŸ“‰ **ê°€ê²© ê¸‰ë½! {price_change_percent:+.2f}%**"
        color = COLOR_RED

    if alert_trigger:
        long_tf_df = get_longer_timeframe_data_sync(
            ticker, LONG_TIMEFRAME, pg_hook, LONG_TIMEFRAME_CANDLES_LIMIT
        )
        short_term_signal_type = f"price_{'bullish' if alert_trigger == 'ê¸‰ë“±' else 'bearish'}"
        context_analysis = analyze_long_term_context_for_signal(
            short_term_signal_type, latest_close, long_tf_df
        )

        logger.info(
            f"PRICE ALERT for {ticker}: {alert_trigger} ({price_change_percent:+.2f}%) Price: {latest_close}, Prev: {previous_close}"
        )

        candle_time_str = pendulum.instance(latest_candle_ts).strftime("%Y-%m-%d %H:%M:%S UTC")

        explanation = ""
        action_suggestion = ""
        if alert_trigger == "ê¸‰ë“±":
            explanation = "ë‹¨ê¸°ì ìœ¼ë¡œ ë§¤ìˆ˜ì„¸ê°€ ê°•í•˜ê²Œ ìœ ì…ë˜ì—ˆìŒì„ ì˜ë¯¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            action_suggestion = "ì¶”ê²© ë§¤ìˆ˜ë³´ë‹¤ëŠ” ì¡°ì • ì‹œ ë§¤ìˆ˜ ë˜ëŠ” ë‹¨ê¸° ì €í•­ì„  í™•ì¸."
        elif alert_trigger == "ê¸‰ë½":
            explanation = "ë‹¨ê¸°ì ìœ¼ë¡œ ë§¤ë„ì„¸ê°€ ê°•í•˜ê²Œ ë‚˜íƒ€ë‚¬ìŒì„ ì˜ë¯¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            action_suggestion = "ì„£ë¶€ë¥¸ ë§¤ìˆ˜ë³´ë‹¤ëŠ” ì§€ì§€ í™•ì¸ í›„ ì ‘ê·¼ ë˜ëŠ” ë‹¨ê¸° ë°˜ë“± ë…¸ë¦¬ê¸°."

        payload = {
            "username": f"ChartBeacon Price Alert ({context_analysis.get('signal_strength','N/A').upper()})",
            "embeds": [
                {
                    "title": f"ğŸš¨ [{ticker}] 5ë¶„ë´‰ ê°€ê²© ë³€ë™: {alert_trigger}",
                    "description": alert_description_prefix,
                    "color": context_analysis.get("color", color),
                    "fields": [
                        {"name": "í˜„ì¬ê°€", "value": f"{latest_close:,.2f}", "inline": True},
                        {
                            "name": "ë³€ë™ë¥ ",
                            "value": f"{price_change_percent:+.2f}%",
                            "inline": True,
                        },
                        {"name": "ê¸°ì¤€ ì‹œê°„ (5ë¶„ë´‰)", "value": candle_time_str, "inline": False},
                        {
                            "name": f"ğŸ“Š {LONG_TIMEFRAME.upper()} ì»¨í…ìŠ¤íŠ¸",
                            "value": context_analysis.get("message", "ë¶„ì„ ì •ë³´ ì—†ìŒ"),
                            "inline": False,
                        },
                        {"name": "ğŸ’¡ 5ë¶„ë´‰ ì˜ë¯¸", "value": explanation, "inline": False},
                        {"name": "ğŸ¤” ëŒ€ì‘ ì „ëµ ì œì•ˆ", "value": action_suggestion, "inline": False},
                        {
                            "name": "ğŸ” ì¶”ê°€ í™•ì¸",
                            "value": "ì¼ë´‰ ì°¨íŠ¸ì—ì„œ í˜„ì¬ ì¶”ì„¸ ë° ì£¼ìš” ì§€ì§€/ì €í•­ì„ ì„ í•¨ê»˜ í™•ì¸í•˜ì„¸ìš”.",
                            "inline": False,
                        },
                    ],
                    "timestamp": pendulum.now("UTC").to_iso8601_string(),
                    "footer": {"text": "íˆ¬ìëŠ” í•­ìƒ ì‹ ì¤‘í•˜ê²Œ! ë³¸ ì •ë³´ëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤."},
                }
            ],
        }
        send_discord_alert(payload, ticker, f"Price {alert_trigger}")
    else:
        logger.debug(
            f"No significant 5m price change for {ticker}. Change: {price_change_percent:.2f}%"
        )


def check_volume_alert_for_symbol(ticker: str, pg_hook: PostgresHook):
    """Checks for significant volume spikes for a given ticker."""
    sql = """
    SELECT c.ts, c.volume
    FROM candles_raw c
    JOIN symbols s ON c.symbol_id = s.id
    WHERE s.ticker = %(ticker)s AND c.timeframe = '5m'
    ORDER BY c.ts DESC
    LIMIT %(limit)s;
    """
    try:
        candles = pg_hook.get_records(
            sql, parameters={"ticker": ticker, "limit": VOLUME_AVG_PERIOD + 1}
        )
    except Exception as e:
        logger.error(f"DB error fetching candles for volume alert ({ticker}): {e}", exc_info=True)
        return

    if (
        not candles or len(candles) < VOLUME_AVG_PERIOD + 1
    ):  # Need at least one current and enough for average
        logger.info(
            f"Not enough 5m candle data for {ticker} to check volume alert (found {len(candles) if candles else 0}, need {VOLUME_AVG_PERIOD + 1})."
        )
        return

    latest_candle_ts, latest_volume_val = candles[0]
    previous_volumes_val = [candle[1] for candle in candles[1:]]

    try:
        latest_volume = float(latest_volume_val)
        previous_volumes = [float(v) for v in previous_volumes_val]
    except (ValueError, TypeError) as e:
        logger.error(
            f"Invalid volume data for {ticker}: {e}. Latest: {latest_volume_val}, Previous: {previous_volumes_val}"
        )
        return

    if not previous_volumes:
        logger.info(f"Not enough previous 5m volume data for {ticker} to calculate average.")
        return

    avg_volume = sum(previous_volumes) / len(previous_volumes)
    volume_factor = 0.0

    if avg_volume == 0:
        if latest_volume > 0:
            volume_factor = float("inf")  # Represent as a very large spike
            logger.info(
                f"Average 5m volume is 0 for {ticker}, current volume is {latest_volume}. Treating as a spike."
            )
        else:
            logger.debug(f"Average 5m volume and current volume are 0 for {ticker}. No spike.")
            return  # No alert if both are zero
    else:
        volume_factor = latest_volume / avg_volume

    alert_trigger = None
    if volume_factor >= VOLUME_SPIKE_FACTOR:
        alert_trigger = "ê±°ë˜ëŸ‰ ê¸‰ì¦"

    if alert_trigger:
        long_tf_df = get_longer_timeframe_data_sync(
            ticker, LONG_TIMEFRAME, pg_hook, LONG_TIMEFRAME_CANDLES_LIMIT
        )
        context_analysis = analyze_long_term_context_for_signal(
            "volume_spike", latest_volume, long_tf_df
        )

        logger.info(
            f"VOLUME ALERT for {ticker}: Factor {volume_factor:.2f}, Current: {latest_volume}, Avg: {avg_volume:.2f}"
        )
        desc_detail = f"{volume_factor:.2f}ë°° ì¦ê°€" + (
            " (í‰ê·  0 ëŒ€ë¹„)" if avg_volume == 0 and latest_volume > 0 else ""
        )
        desc_main = f"ğŸ“ˆ **{alert_trigger}! {desc_detail}**"
        explanation = (
            "í‰ì†Œë³´ë‹¤ ë§ì€ ê´€ì‹¬ ë˜ëŠ” íŠ¹ì • ì£¼ì²´ì˜ ê±°ë˜ ë°œìƒ ê°€ëŠ¥ì„±. ê°€ê²© ë³€ë™ ì‹ ë¢°ë„ ì¦ê°€/ê°ì†Œ ìš”ì¸."
        )
        action_suggestion = (
            "ê±°ë˜ëŸ‰ ì¦ê°€ ë°©í–¥ìœ¼ë¡œì˜ ì¶”ì„¸ ì§€ì† ë˜ëŠ” ë°˜ì „ ê°€ëŠ¥ì„± ì—¼ë‘. ê°€ê²© ì›€ì§ì„ê³¼ í•¨ê»˜ íŒë‹¨."
        )
        candle_time_str = pendulum.instance(latest_candle_ts).strftime("%Y-%m-%d %H:%M:%S UTC")

        payload = {
            "username": "ChartBeacon Volume Alert",
            "embeds": [
                {
                    "title": f"ğŸ“Š [{ticker}] 5ë¶„ë´‰ {alert_trigger}",
                    "description": desc_main,
                    "color": context_analysis.get("color", COLOR_BLUE),
                    "fields": [
                        {"name": "í˜„ì¬ ê±°ë˜ëŸ‰", "value": f"{latest_volume:,.0f}", "inline": True},
                        {
                            "name": f"{VOLUME_AVG_PERIOD}ë´‰ í‰ê· ",
                            "value": f"{avg_volume:,.0f}",
                            "inline": True,
                        },
                        {"name": "ê¸°ì¤€ ì‹œê°„ (5ë¶„ë´‰)", "value": candle_time_str, "inline": False},
                        {
                            "name": f"ğŸ“Š {LONG_TIMEFRAME.upper()} ì»¨í…ìŠ¤íŠ¸",
                            "value": context_analysis.get("message", "ë¶„ì„ ì •ë³´ ì—†ìŒ"),
                            "inline": False,
                        },
                        {"name": "ğŸ’¡ 5ë¶„ë´‰ ì˜ë¯¸", "value": explanation, "inline": False},
                        {"name": "ğŸ¤” ëŒ€ì‘ ì „ëµ ì œì•ˆ", "value": action_suggestion, "inline": False},
                    ],
                    "timestamp": pendulum.now("UTC").to_iso8601_string(),
                    "footer": {"text": "íˆ¬ìëŠ” í•­ìƒ ì‹ ì¤‘í•˜ê²Œ! ë³¸ ì •ë³´ëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤."},
                }
            ],
        }
        send_discord_alert(payload, ticker, "Volume spike")
    else:
        logger.debug(
            f"No significant 5m volume spike for {ticker}. Factor: {volume_factor:.2f if avg_volume > 0 else 'N/A'}"
        )


def check_bollinger_band_alert_for_symbol(ticker: str, pg_hook: PostgresHook):
    """Checks for Bollinger Band breakouts for a given ticker."""
    sql = """
    SELECT c.ts, c.close
    FROM candles_raw c
    JOIN symbols s ON c.symbol_id = s.id
    WHERE s.ticker = %(ticker)s AND c.timeframe = '5m'
    ORDER BY c.ts DESC
    LIMIT %(limit)s;
    """
    try:
        candles_records = pg_hook.get_records(
            sql, parameters={"ticker": ticker, "limit": BBANDS_PERIOD + 5}
        )
    except Exception as e:
        logger.error(f"DB error fetching candles for BBands alert ({ticker}): {e}", exc_info=True)
        return

    if not candles_records or len(candles_records) < BBANDS_PERIOD:
        logger.info(
            f"Not enough 5m candle data for {ticker} to calculate BBands (found {len(candles_records) if candles_records else 0}, need {BBANDS_PERIOD})."
        )
        return

    # Convert to DataFrame, newest first
    df = pd.DataFrame(candles_records, columns=["ts", "close"])
    df["ts"] = pd.to_datetime(df["ts"])
    df["close"] = pd.to_numeric(df["close"], errors="coerce")
    df.dropna(subset=["close"], inplace=True)  # Drop rows where close is NaN after conversion

    if len(df) < BBANDS_PERIOD:  # Check again after dropping NaNs
        logger.info(
            f"Not enough valid 5m candle data for {ticker} after NaN drop (found {len(df)}, need {BBANDS_PERIOD})."
        )
        return

    # Data is newest first, reverse for typical TA calculations (oldest first)
    df = df.iloc[::-1].reset_index(drop=True)

    # Calculate Bollinger Bands
    df["sma"] = df["close"].rolling(window=BBANDS_PERIOD).mean()
    df["stddev"] = df["close"].rolling(window=BBANDS_PERIOD).std()
    df["upper_band"] = df["sma"] + (BBANDS_STD_DEV * df["stddev"])
    df["lower_band"] = df["sma"] - (BBANDS_STD_DEV * df["stddev"])

    if (
        df.empty
        or len(df) < 1
        or pd.isna(df.iloc[-1]["close"])
        or pd.isna(df.iloc[-1]["upper_band"])
        or pd.isna(df.iloc[-1]["lower_band"])
    ):
        logger.info(
            f"Could not calculate BBands for {ticker}, possibly due to insufficient data or NaNs in recent bands."
        )
        return

    latest_candle = df.iloc[-1]  # Current candle (most recent)
    # Previous candle's relation to bands can be checked with df.iloc[-2] if needed for "breakout from within" logic

    latest_ts = latest_candle["ts"]
    latest_close = latest_candle["close"]
    upper_band = latest_candle["upper_band"]
    lower_band = latest_candle["lower_band"]
    sma = latest_candle["sma"]

    alert_type = None
    description = None
    color = COLOR_PURPLE

    # Check for breakout: current close is outside the bands.
    # More robust: check if *previous* close was inside, and current is outside.
    # For now, simple "outside" check for the latest point.
    if latest_close > upper_band:
        alert_type = "BB ìƒë‹¨ ëŒíŒŒ"
        description = "ğŸ“ˆ **ë³¼ë¦°ì €ë°´ë“œ ìƒë‹¨ ëŒíŒŒ!**"
        color = COLOR_GREEN
    elif latest_close < lower_band:
        alert_type = "BB í•˜ë‹¨ ëŒíŒŒ"
        description = "ğŸ“‰ **ë³¼ë¦°ì €ë°´ë“œ í•˜ë‹¨ ëŒíŒŒ!**"
        color = COLOR_RED

    if alert_type:
        long_tf_df = get_longer_timeframe_data_sync(
            ticker, LONG_TIMEFRAME, pg_hook, LONG_TIMEFRAME_CANDLES_LIMIT
        )
        short_term_signal_type = (
            f"bb_{'upper_break' if alert_type == 'BB ìƒë‹¨ ëŒíŒŒ' else 'lower_break'}"
        )
        context_analysis = analyze_long_term_context_for_signal(
            short_term_signal_type, latest_close, long_tf_df
        )

        logger.info(
            f"BBANDS ALERT for {ticker}: {alert_type}. Price: {latest_close:.2f}, Upper: {upper_band:.2f}, Lower: {lower_band:.2f}"
        )

        candle_time_str = pendulum.instance(latest_ts).strftime("%Y-%m-%d %H:%M:%S UTC")

        explanation = ""
        action_suggestion = ""
        if alert_type == "BB ìƒë‹¨ ëŒíŒŒ":
            explanation = "ê°€ê²©ì´ ë‹¨ê¸°ì ìœ¼ë¡œ ê³¼ë§¤ìˆ˜ êµ¬ê°„ì— ì§„ì…í–ˆê±°ë‚˜, ê°•í•œ ìƒìŠ¹ ì¶”ì„¸ì˜ ì‹œì‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³€ë™ì„± í™•ëŒ€ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤."
            action_suggestion = "ëŒíŒŒ í›„ ì§€ì§€ í™•ì¸ ë˜ëŠ” ì¶”ì„¸ ì¶”ì¢…."
        elif alert_type == "BB í•˜ë‹¨ ëŒíŒŒ":
            explanation = "ê°€ê²©ì´ ë‹¨ê¸°ì ìœ¼ë¡œ ê³¼ë§¤ë„ êµ¬ê°„ì— ì§„ì…í–ˆê±°ë‚˜, ê°•í•œ í•˜ë½ ì¶”ì„¸ì˜ ì‹œì‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³€ë™ì„± í™•ëŒ€ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤."
            action_suggestion = "ëŒíŒŒ í›„ ì €í•­ í™•ì¸ ë˜ëŠ” ê¸°ìˆ ì  ë°˜ë“± ê³ ë ¤."

        payload = {
            "username": f"ChartBeacon BB Alert ({context_analysis.get('signal_strength','N/A').upper()})",
            "embeds": [
                {
                    "title": f"ğŸŸ£ [{ticker}] 5ë¶„ë´‰ {alert_type}",
                    "description": description,
                    "color": context_analysis.get("color", color),
                    "fields": [
                        {"name": "í˜„ì¬ê°€", "value": f"{latest_close:,.2f}", "inline": True},
                        {"name": "ìƒë‹¨ë°´ë“œ", "value": f"{upper_band:,.2f}", "inline": True},
                        {"name": "í•˜ë‹¨ë°´ë“œ", "value": f"{lower_band:,.2f}", "inline": True},
                        {"name": "ì¤‘ì‹¬ì„ (SMA)", "value": f"{sma:,.2f}", "inline": True},
                        {"name": "ê¸°ì¤€ ì‹œê°„ (5ë¶„ë´‰)", "value": candle_time_str, "inline": False},
                        {
                            "name": f"ğŸ“Š {LONG_TIMEFRAME.upper()} ì»¨í…ìŠ¤íŠ¸",
                            "value": context_analysis.get("message", "ë¶„ì„ ì •ë³´ ì—†ìŒ"),
                            "inline": False,
                        },
                        {"name": "ğŸ’¡ 5ë¶„ë´‰ ì˜ë¯¸", "value": explanation, "inline": False},
                        {"name": "ğŸ¤” ëŒ€ì‘ ì „ëµ ì œì•ˆ", "value": action_suggestion, "inline": False},
                    ],
                    "timestamp": pendulum.now("UTC").to_iso8601_string(),
                    "footer": {"text": "íˆ¬ìëŠ” í•­ìƒ ì‹ ì¤‘í•˜ê²Œ! ë³¸ ì •ë³´ëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤."},
                }
            ],
        }
        send_discord_alert(payload, ticker, alert_type)
    else:
        logger.debug(
            f"No BBands breakout for {ticker}. Price: {latest_close:.2f}, Upper: {upper_band:.2f}, Lower: {lower_band:.2f}"
        )


def check_support_resistance_alert_for_symbol(ticker: str, pg_hook: PostgresHook):
    """Checks for touches or breaks of dynamic support/resistance levels."""
    sql = """
    SELECT c.ts, c.high, c.low, c.close -- Added close for context
    FROM candles_raw c
    JOIN symbols s ON c.symbol_id = s.id
    WHERE s.ticker = %(ticker)s AND c.timeframe = '5m'
    ORDER BY c.ts DESC
    LIMIT %(limit)s;
    """
    try:
        # Fetch SR_LOOKBACK_PERIOD for S/R calculation, and one more (current candle)
        candles_records = pg_hook.get_records(
            sql, parameters={"ticker": ticker, "limit": SR_LOOKBACK_PERIOD + 1}
        )
    except Exception as e:
        logger.error(f"DB error fetching candles for S/R alert ({ticker}): {e}", exc_info=True)
        return

    if not candles_records or len(candles_records) <= 1:  # Need at least current and some history
        logger.info(
            f"Not enough 5m candle data for {ticker} to check S/R (found {len(candles_records) if candles_records else 0}, need >1)."
        )
        return

    df = pd.DataFrame(candles_records, columns=["ts", "high", "low", "close"])
    df["ts"] = pd.to_datetime(df["ts"])
    for col in ["high", "low", "close"]:
        df[col] = pd.to_numeric(df[col], errors="coerce")
    df.dropna(inplace=True)

    if len(df) <= 1:  # Need current and some lookback data
        logger.info(
            f"Not enough valid 5m candle data for {ticker} after NaN drop for S/R (found {len(df)})."
        )
        return

    latest_candle = df.iloc[0]  # Newest candle is at the top of the records from DB
    historical_candles = df.iloc[
        1 : SR_LOOKBACK_PERIOD + 1
    ]  # The lookback period, excluding the current one for S/R calculation

    if historical_candles.empty:
        logger.info(f"Not enough historical data for S/R calculation for {ticker} (after latest).")
        return

    dynamic_support = historical_candles["low"].min()
    dynamic_resistance = historical_candles["high"].max()

    latest_ts = latest_candle["ts"]
    latest_high = latest_candle["high"]
    latest_low = latest_candle["low"]
    latest_close = latest_candle["close"]

    alert_type = None
    description = None
    level_touched = None
    color = COLOR_BLUE

    # Check for touch/break. Alert if current low hits/breaks support OR current high hits/breaks resistance.
    # Could add a small tolerance (e.g., within 0.1% of the level)
    if latest_low <= dynamic_support:
        alert_type = "ì§€ì§€ì„  í„°ì¹˜/ì´íƒˆ"
        description = f"ğŸ›¡ï¸ **ì§€ì§€ì„ ({dynamic_support:,.2f}) í„°ì¹˜ ë˜ëŠ” í•˜í–¥ ì´íƒˆ!**"
        level_touched = f"ì§€ì§€ {dynamic_support:,.2f}"
        color = COLOR_RED  # Potentially bearish
    elif latest_high >= dynamic_resistance:
        alert_type = "ì €í•­ì„  í„°ì¹˜/ëŒíŒŒ"
        description = f"âš”ï¸ **ì €í•­ì„ ({dynamic_resistance:,.2f}) í„°ì¹˜ ë˜ëŠ” ìƒí–¥ ëŒíŒŒ!**"
        level_touched = f"ì €í•­ {dynamic_resistance:,.2f}"
        color = COLOR_GREEN  # Potentially bullish

    if alert_type:
        long_tf_df = get_longer_timeframe_data_sync(
            ticker, LONG_TIMEFRAME, pg_hook, LONG_TIMEFRAME_CANDLES_LIMIT
        )
        short_term_signal_type = (
            f"sr_{'support_touch' if 'ì§€ì§€ì„ ' in alert_type else 'resistance_touch'}"
        )
        context_analysis = analyze_long_term_context_for_signal(
            short_term_signal_type, latest_close, long_tf_df
        )

        logger.info(
            f"S/R ALERT for {ticker}: {alert_type}. Low: {latest_low:.2f}, High: {latest_high:.2f}, Support: {dynamic_support:.2f}, Resistance: {dynamic_resistance:.2f}"
        )

        candle_time_str = pendulum.instance(latest_ts).strftime("%Y-%m-%d %H:%M:%S UTC")

        explanation = ""
        action_suggestion = ""
        if "ì§€ì§€ì„ " in alert_type:
            explanation = f"ìµœê·¼ {SR_LOOKBACK_PERIOD}ê°œ ë´‰ì˜ ìµœì €ê°€({dynamic_support:,.2f}) ë¶€ê·¼ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ë‹¨ê¸°ì  ë°˜ë“± ê°€ëŠ¥ì„±ì´ ìˆê±°ë‚˜, ì´íƒˆ ì‹œ ì¶”ê°€ í•˜ë½ì´ ë‚˜ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            action_suggestion = (
                "ì§€ì§€ ì—¬ë¶€ í™•ì¸ (ê¼¬ë¦¬, ê±°ë˜ëŸ‰). ì´íƒˆ ì‹œ ì†ì ˆ ë˜ëŠ” ê´€ë§. ë°˜ë“± ì‹œ ë‹¨ê¸° ë§¤ìˆ˜ ê³ ë ¤."
            )
        elif "ì €í•­ì„ " in alert_type:
            explanation = f"ìµœê·¼ {SR_LOOKBACK_PERIOD}ê°œ ë´‰ì˜ ìµœê³ ê°€({dynamic_resistance:,.2f}) ë¶€ê·¼ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ë‹¨ê¸°ì  ì¡°ì • ê°€ëŠ¥ì„±ì´ ìˆê±°ë‚˜, ëŒíŒŒ ì‹œ ì¶”ê°€ ìƒìŠ¹ì´ ë‚˜ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            action_suggestion = (
                "ì €í•­ ëŒíŒŒ ì—¬ë¶€ í™•ì¸ (ê±°ë˜ëŸ‰ ë™ë°˜). ëŒíŒŒ ì‹œ ì¶”ê²© ë§¤ìˆ˜ ê³ ë ¤, ì‹¤íŒ¨ ì‹œ ë§¤ë„ ë˜ëŠ” ê´€ë§."
            )

        payload = {
            "username": f"ChartBeacon S/R Alert ({context_analysis.get('signal_strength','N/A').upper()})",
            "embeds": [
                {
                    "title": f"ğŸ›¡ï¸âš”ï¸ [{ticker}] 5ë¶„ë´‰ {alert_type}",
                    "description": description,
                    "color": context_analysis.get("color", color),
                    "fields": [
                        {"name": "í˜„ì¬ ì €ê°€", "value": f"{latest_low:,.2f}", "inline": True},
                        {"name": "í˜„ì¬ ê³ ê°€", "value": f"{latest_high:,.2f}", "inline": True},
                        {"name": "í˜„ì¬ ì¢…ê°€", "value": f"{latest_close:,.2f}", "inline": True},
                        {"name": "ê°ì§€ëœ ë ˆë²¨", "value": level_touched, "inline": True},
                        {"name": "ê¸°ì¤€ ì‹œê°„ (5ë¶„ë´‰)", "value": candle_time_str, "inline": False},
                        {
                            "name": f"ğŸ“Š {LONG_TIMEFRAME.upper()} ì»¨í…ìŠ¤íŠ¸",
                            "value": context_analysis.get("message", "ë¶„ì„ ì •ë³´ ì—†ìŒ"),
                            "inline": False,
                        },
                        {"name": "ğŸ’¡ 5ë¶„ë´‰ ì˜ë¯¸", "value": explanation, "inline": False},
                        {"name": "ğŸ¤” ëŒ€ì‘ ì „ëµ ì œì•ˆ", "value": action_suggestion, "inline": False},
                    ],
                    "timestamp": pendulum.now("UTC").to_iso8601_string(),
                    "footer": {"text": "íˆ¬ìëŠ” í•­ìƒ ì‹ ì¤‘í•˜ê²Œ! ë³¸ ì •ë³´ëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤."},
                }
            ],
        }
        send_discord_alert(payload, ticker, alert_type)
    else:
        logger.debug(
            f"No S/R touch/break for {ticker}. Low: {latest_low:.2f}, High: {latest_high:.2f}, Support: {dynamic_support:.2f}, Resistance: {dynamic_resistance:.2f}"
        )


def process_alerts_for_tickers_task(ti, alert_check_function_name_str: str, task_name_suffix: str):
    """Generic task to process alerts for a list of tickers using a specific check function by name."""
    active_tickers = ti.xcom_pull(task_ids="get_active_symbols_task_id")
    if not active_tickers:
        logger.info(f"No active symbols to process for {task_name_suffix} alerts.")
        raise AirflowSkipException(f"No active symbols found for {task_name_suffix}.")

    pg_hook = PostgresHook(postgres_conn_id=POSTGRES_CONN_ID)

    # ë¬¸ìì—´ë¡œ ë°›ì€ í•¨ìˆ˜ ì´ë¦„ì„ ì‹¤ì œ í•¨ìˆ˜ ê°ì²´ë¡œ ë§¤í•‘
    alert_function_map = {
        "check_price_alert_for_symbol": check_price_alert_for_symbol,
        "check_volume_alert_for_symbol": check_volume_alert_for_symbol,
        "check_bollinger_band_alert_for_symbol": check_bollinger_band_alert_for_symbol,
        "check_support_resistance_alert_for_symbol": check_support_resistance_alert_for_symbol,
    }
    alert_check_function = alert_function_map.get(alert_check_function_name_str)

    if not alert_check_function:
        logger.error(f"Unknown alert check function name: {alert_check_function_name_str}")
        return

    for ticker in active_tickers:
        try:
            alert_check_function(ticker, pg_hook)  # pg_hook ì „ë‹¬
        except Exception as e:
            logger.error(
                f"Error processing {task_name_suffix} alert for {ticker}: {e}", exc_info=True
            )


with DAG(
    dag_id="smart_alerts_5m_v1",
    start_date=pendulum.datetime(2024, 1, 1, tz="Asia/Seoul"),
    schedule="*/5 * * * *",
    catchup=False,
    tags=["smart-alerts", "filtered", "5m", "1h-context"],
    doc_md="""
    ### ìŠ¤ë§ˆíŠ¸ ì•Œë¦¼ DAG (5ë¶„ ì£¼ê¸°, 1ì‹œê°„ë´‰ ì»¨í…ìŠ¤íŠ¸ í•„í„°ë§)
    - **ëª©í‘œ**: í™œì„± ì‹¬ë³¼ì— ëŒ€í•´ 5ë¶„ë´‰ ê¸°ì¤€ ì£¼ìš” ë³€ë™ ì‚¬í•­ì„ ê°ì§€í•˜ê³ , 1ì‹œê°„ë´‰ ë°ì´í„°ë¥¼ í†µí•´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í•„í„°ë§ëœ ì•Œë¦¼ì„ Discordë¡œ ì „ì†¡.
    - **ì‹¤í–‰ ì£¼ê¸°**: ë§¤ 5ë¶„.
    - **ì£¼ìš” ë¡œì§**:
        1.  `get_active_symbols_task_id`: DBì—ì„œ í™œì„± ì‹¬ë³¼ ëª©ë¡ ì¡°íšŒ.
        2.  ê° ì‹¬ë³¼ì— ëŒ€í•´ 5ë¶„ë´‰ ì•Œë¦¼ ì¡°ê±´ í™•ì¸ (ê°€ê²©, ê±°ë˜ëŸ‰, BB, S/R).
        3.  ì¡°ê±´ ë°œìƒ ì‹œ, í•´ë‹¹ ì‹¬ë³¼ì˜ 1ì‹œê°„ë´‰ ë°ì´í„° (OHLCV, EMA20, EMA60) ì¡°íšŒ.
        4.  1ì‹œê°„ë´‰ ì»¨í…ìŠ¤íŠ¸(ì¶”ì„¸, ì£¼ìš” ì´í‰ì„ ê³¼ì˜ ê´€ê³„)ë¥¼ ë¶„ì„í•˜ì—¬ 5ë¶„ë´‰ ì‹ í˜¸ì˜ ê°•ë„ í‰ê°€.
        5.  í•„í„°ë§ëœ (ë˜ëŠ” ê°•í™”/ì•½í™” ì •ë³´ê°€ ì¶”ê°€ëœ) ì•Œë¦¼ì„ Discordë¡œ ì „ì†¡.
    - **ì•Œë¦¼ ì±„ë„**: Discord (í™˜ê²½ë³€ìˆ˜ `DISCORD_WEBHOOK_URL` í•„ìš”).
    - **DB ì—°ê²°**: Airflow Connection `postgres_default`.
    """,
) as dag:

    get_active_symbols_op = PythonOperator(
        task_id="get_active_symbols_task_id",
        python_callable=get_active_symbols_task,
    )

    process_price_alerts_op = PythonOperator(
        task_id="process_price_alerts_task_id",
        python_callable=process_alerts_for_tickers_task,
        op_kwargs={
            "alert_check_function_name_str": "check_price_alert_for_symbol",
            "task_name_suffix": "price",
        },
        provide_context=True,
    )

    process_volume_alerts_op = PythonOperator(
        task_id="process_volume_alerts_task_id",
        python_callable=process_alerts_for_tickers_task,
        op_kwargs={
            "alert_check_function_name_str": "check_volume_alert_for_symbol",
            "task_name_suffix": "volume",
        },
        provide_context=True,
    )

    process_bbands_alerts_op = PythonOperator(
        task_id="process_bbands_alerts_task_id",
        python_callable=process_alerts_for_tickers_task,
        op_kwargs={
            "alert_check_function_name_str": "check_bollinger_band_alert_for_symbol",
            "task_name_suffix": "bbands",
        },
        provide_context=True,
    )

    process_sr_alerts_op = PythonOperator(
        task_id="process_sr_alerts_task_id",
        python_callable=process_alerts_for_tickers_task,
        op_kwargs={
            "alert_check_function_name_str": "check_support_resistance_alert_for_symbol",
            "task_name_suffix": "sr",
        },
        provide_context=True,
    )

    get_active_symbols_op >> [
        process_price_alerts_op,
        process_volume_alerts_op,
        process_bbands_alerts_op,
        process_sr_alerts_op,
    ]
